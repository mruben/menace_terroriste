{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHARGEMENT DES BIBLIOTHEQUES\n",
    "############################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import geopandas as gpd\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FONCTIONS UTILES\n",
    "############################################################\n",
    "\n",
    "##\n",
    "# CHARGEMENT DE FICHIERS JSON\n",
    "\n",
    "# Fonction qui permet de charger un fichier json dans un dictionnaire\n",
    "def load_json_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "##\n",
    "# CHARGEMENT DU DATAFRAME\n",
    "\n",
    "# On charge les données dans un dataframe \"df\"\n",
    "def load_dataset(path):\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "##\n",
    "# FILTRAGE DE COLONNES\n",
    "\n",
    "# On récupère ici seulement les évènements qui nous intéressent, ceux liés à des violences politiques\n",
    "# On conserve 'Strategic developments' car elle permet de capturer le contexte\n",
    "def columns_filtering(df):\n",
    "    events_filter = ['Battles', 'Explosions/Remote violence',\n",
    "                    'Violence against civilians', 'Strategic developments']\n",
    "\n",
    "    df = df[df['event_type'].isin(events_filter)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "##\n",
    "# CREATION DE NOUVELLES COLONNES\n",
    "\n",
    "def add_new_colums_dates(df):\n",
    "    ##\n",
    "    # On transforme la colonne \"event_date\" en datetime pour la manipuler plus facilement\n",
    "    df['event_date'] = pd.to_datetime(df['event_date'])\n",
    "\n",
    "    # On crée la colonne \"month\" en utilisant l'attribut month de datetime\n",
    "    df['month'] = df['event_date'].dt.month\n",
    "    # On ajoute la colonne juste après \"year\"\n",
    "    df.insert(3, 'month', df.pop('month'))\n",
    "\n",
    "    # On crée la colonne \"day\" en utilisant l'attribut day de datetime\n",
    "    df['day'] = df['event_date'].dt.day\n",
    "    # On ajoute la colonne juste après \"month\"\n",
    "    df.insert(5, 'day', df.pop('day'))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def add_new_colums_actors(df):\n",
    "    ##\n",
    "    # On charge les données du fichier json \"actor_type\" dans un dictionnaire\n",
    "    # qui associe les valeurs des colonnes \"inter1\" et \"inter2\"\n",
    "    # au nom de chaque catégorie d'acteur (source : codebook ACLED)\n",
    "    actor_type = load_json_file(\"../references/actor_type.json\")\n",
    "\n",
    "    # On convertit les clés du dictionnaire en entiers\n",
    "    actor_type = {int(k): v for k, v in actor_type.items()}\n",
    "\n",
    "    # On ajoute les colonnes \"actor1_type\" et \"actor2_type\" au dataframe\n",
    "    df['actor1_type'] = df['inter1'].map(actor_type)\n",
    "    df['actor2_type'] = df['inter2'].map(actor_type)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_new_colums_interaction(df):\n",
    "    ##\n",
    "    # On charge les données du fichier json \"interaction_type\" dans un dictionnaire\n",
    "    # associant aux valeurs de la colonne \"interaction\"\n",
    "    # les 2 acteurs impliqués dans une confrontation (source : codebook ACLED)\n",
    "    interaction_type = load_json_file(\"../references/interaction_type.json\")\n",
    "\n",
    "    # On convertit les clés du dictionnaire en entiers\n",
    "    interaction_type = {int(k): v for k, v in interaction_type.items()}\n",
    "\n",
    "    # On ajoute une colonne \"interaction_type\" au dataframe\n",
    "    df['interaction_type'] = df['interaction'].map(interaction_type)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_new_colums_terrorist_group(df):\n",
    "    # On crée une nouvelle colonne qui indique si pour un évènement l'un des\n",
    "    # acteurs est une organisation terroriste\n",
    "    # On charge les données du fichier json \"terrorist_group_filiation\"\n",
    "    # dans un dictionnaire associant organisation terroriste et organisation mère\n",
    "    terrorist_group_filiation = load_json_file(\"../references/terrorist_group_filiation.json\")\n",
    "\n",
    "    # On crée une liste contenant les organisations terroristes à partir des indices de ce dictionnaire\n",
    "    terrorist_groups = list(terrorist_group_filiation.keys())\n",
    "\n",
    "    # On crée une fonction pour vérifier si un acteur est une organisation terroriste\n",
    "    def is_terrorist_actor(actor):\n",
    "        return actor in terrorist_groups\n",
    "\n",
    "    # On ajoute la colonne \"is_terrorist_group_related\" au dataframe\n",
    "    df['is_terrorist_group_related'] = (df['actor1'].apply(is_terrorist_actor) |\n",
    "                                df['assoc_actor_1'].apply(is_terrorist_actor) |\n",
    "                                df['actor2'].apply(is_terrorist_actor) |\n",
    "                                df['assoc_actor_2'].apply(is_terrorist_actor)).astype(int)\n",
    "\n",
    "    # On crée une fonction de mapping pour associer les valeurs du dictionnaire aux acteurs\n",
    "    # S'il n'y a pas de valeur on retourne \"None\" car cela veut simplement dire que l'évènement\n",
    "    # n'est pas lié à une organisation terroriste et qu'il n'y a donc pas de lien de filiation\n",
    "    # avec une organisation mère\n",
    "    def map_filiation(row):\n",
    "        for actor in ['actor1', 'assoc_actor_1', 'actor2', 'assoc_actor_2']:\n",
    "            if row[actor] in terrorist_group_filiation:\n",
    "                return terrorist_group_filiation[row[actor]]\n",
    "        return \"None\"\n",
    "\n",
    "    # On ajoute la colonne \"terrorist_group_filiation\" au dataframe\n",
    "    df['terrorist_group_filiation'] = df.apply(map_filiation, axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_new_colums_pmc_group(df):\n",
    "    # On crée une nouvelle colonne qui indique si pour un évènement l'un\n",
    "    # des acteurs est une pmc russe\n",
    "    pmc_groups = ['Wagner Group']\n",
    "\n",
    "    # On crée une fonction pour vérifier si un acteur est une pmc russe\n",
    "    def is_pmc_actor(actor):\n",
    "        return actor in pmc_groups\n",
    "\n",
    "    # On ajoute la colonne \"is_pmc_related\" au dataframe\n",
    "    df['is_pmc_related'] = (df['actor1'].apply(is_pmc_actor) |\n",
    "                                df['assoc_actor_1'].apply(is_pmc_actor) |\n",
    "                                df['actor2'].apply(is_pmc_actor) |\n",
    "                                df['assoc_actor_2'].apply(is_pmc_actor)).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "##\n",
    "# SUPPRESSION DE COLONNES\n",
    "\n",
    "def delete_columns(df):\n",
    "    # On supprime les colonnes qui ne nous serons d'aucune utilité\n",
    "    columns_to_drop = [\n",
    "        'time_precision',\n",
    "        'disorder_type',\n",
    "        'sub_event_type',\n",
    "        'actor1',\n",
    "        'assoc_actor_1',\n",
    "        'actor2',\n",
    "        'assoc_actor_2',\n",
    "        'inter1',\n",
    "        'inter2',\n",
    "        'interaction',\n",
    "        'admin2',\n",
    "        'admin3',\n",
    "        'iso',\n",
    "        'region',\n",
    "        'location',\n",
    "        'latitude',\n",
    "        'longitude',\n",
    "        'geo_precision',\n",
    "        'source',\n",
    "        'source_scale',\n",
    "        'notes',\n",
    "        'tags',\n",
    "        'timestamp',\n",
    "        'civilian_targeting',\n",
    "        'event_id_cnty'\n",
    "    ]\n",
    "\n",
    "    df = df.drop(columns=columns_to_drop, axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "##\n",
    "# GESTION DES VALEURS MANQUANTES\n",
    "\n",
    "def fill_nan_values(df):\n",
    "    # Pour la colonne \"actor2_type\" on va remplacer les valeurs manquantes par \"None\" car cela\n",
    "    # indique juste que dans certains cas qu'il y a un seul acteur et pas un manque de valeur\n",
    "    df['actor2_type'] = df['actor2_type'].fillna(\"None\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "##\n",
    "# Fonction pour mapper les noms de sous-régions aux identifiants de coordonnées\n",
    "def map_regions_to_ids(data, mapping):\n",
    "    data['region_id'] = data['admin1'].map(mapping)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONSTRUCTION DU DATAFRAME HISTORIQUE \"past_data\"\n",
    "############################################################\n",
    "\n",
    "def build_past_data(df):\n",
    "    # On compte les occurences de chaque valeur des colonnes 'actor1_type' et 'actor2_type'\n",
    "    actor_counts = df.melt(id_vars=['event_date', 'country', 'admin1', 'year', 'month', 'is_terrorist_group_related', 'fatalities', 'event_type'], \n",
    "                        value_vars=['actor1_type', 'actor2_type'], \n",
    "                        var_name='actor_role', value_name='actor')\n",
    "\n",
    "    actor_counts = actor_counts.groupby(['country', 'admin1', 'year', 'month', 'actor']).size().unstack(fill_value=0).reset_index()\n",
    "\n",
    "    # On compte les occurences de chaque type d'évènement\n",
    "    event_type_counts = df.pivot_table(index=['country', 'admin1', 'year', 'month'], \n",
    "                                    columns='event_type', \n",
    "                                    aggfunc='size', \n",
    "                                    fill_value=0).reset_index()\n",
    "\n",
    "    # On agrège les données par mois, par pays, par sous-région\n",
    "    past_data = df.groupby(['country', 'admin1', 'year', 'month']).agg(\n",
    "        total_events=('event_date', 'count'),\n",
    "        terrorist_events=('is_terrorist_group_related', 'sum'),\n",
    "        fatalities=('fatalities', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    # On fusionne les variables des acteurs et des types d'évènements avec les données agrégées\n",
    "    past_data = past_data.merge(actor_counts, on=['country', 'admin1', 'year', 'month'], how='left')\n",
    "    past_data = past_data.merge(event_type_counts, on=['country', 'admin1', 'year', 'month'], how='left')\n",
    "\n",
    "    # On supprime les colonnes 'None' et 'Protesters' qui concernent les acteurs mais sont sans intérêt pour notre étude\n",
    "    # ou bien la colonne 'Rebel Groups' qui est dérivée de la variable cible\n",
    "    past_data = past_data.drop(columns=['None', 'Protesters', 'Rebel Groups'], axis=1)\n",
    "\n",
    "    # On crée des features décalées (lags) pour capturer les tendances passées des événements totaux et des événements terroristes\n",
    "    for admin in past_data['admin1'].unique():  # Pour chaque valeur unique dans la colonne 'admin1'\n",
    "        \n",
    "        for lag in range(1, 7):  # Pour chaque décalage (lag) de 1 à 6\n",
    "            lag_total_events = past_data[past_data['admin1'] == admin]['total_events'].shift(lag)  # Crée une série décalée pour 'total_events' pour l'admin actuel\n",
    "            lag_terrorist_events = past_data[past_data['admin1'] == admin]['terrorist_events'].shift(lag)  # Crée une série décalée pour 'terrorist_events' sans filtrer par admin\n",
    "            past_data.loc[past_data['admin1'] == admin, f'total_events_lag_{lag}'] = lag_total_events  # Ajoute la série décalée pour 'total_events' dans une nouvelle colonne pour l'admin actuel\n",
    "            past_data.loc[past_data['admin1'] == admin, f'terrorist_events_lag_{lag}'] = lag_terrorist_events  # Ajoute la série décalée pour 'terrorist_events' dans une nouvelle colonne pour l'admin actuel\n",
    "            past_data[[f'total_events_lag_{lag}', f'terrorist_events_lag_{lag}']] = past_data[\n",
    "                [f'total_events_lag_{lag}', f'terrorist_events_lag_{lag}']\n",
    "                ].fillna(0)  # Remplit les valeurs manquantes dans les colonnes décalées avec des zéros\n",
    "\n",
    "    # On supprime les valeurs NA générées par les lags\n",
    "    # past_data.dropna(inplace=True)  # Optionnel : supprime les lignes contenant des valeurs NA (commenté ici)\n",
    "\n",
    "    # On supprime la colonne \"total_events\" qui est trop corrélée à notre variable cible\n",
    "    past_data = past_data.drop(columns=['total_events'], axis=1)\n",
    "\n",
    "    return past_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRANSFORMATION DES DONNEES DU DATAFRAME \"past_data\"\n",
    "############################################################\n",
    "\n",
    "def past_data_transformation(df):\n",
    "\n",
    "    ##\n",
    "    # On trie notre dataframe par année puis mois dans l'ordre croissant\n",
    "    # pour que les données de test concernent les événements les plus récents\n",
    "    df = df.sort_values(by=['year', 'month'])\n",
    "\n",
    "    # Séparation des variables explicatives de notre variable cible\n",
    "    X = df.drop(columns='terrorist_events', axis=1)\n",
    "    y = df['terrorist_events']\n",
    "\n",
    "    # Division en ensembles d'entraînement et de test avec shuffle à False\n",
    "    # pour que les données de test concernent les événements les plus récents (6 derniers mois)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "    # On sauvegarde une version non encodée de X_test\n",
    "    X_test_no_encoding = X_test\n",
    "\n",
    "\n",
    "    ##\n",
    "    # On standardise les variables numériques exceptées les variables catégorielles\n",
    "    # ainsi que l'année et le mois qui subiront une autre transformation\n",
    "    cat_columns=['country', 'admin1']\n",
    "    X_train_numerical_vars = [col for col in X_train.columns if col not in cat_columns + ['year', 'month']]\n",
    "    X_test_numerical_vars = [col for col in X_test.columns if col not in cat_columns + ['year', 'month']]\n",
    "    # Extraction des données numériques\n",
    "    X_train_numerical = X_train[X_train_numerical_vars].values\n",
    "    X_test_numerical = X_test[X_test_numerical_vars].values\n",
    "\n",
    "    # Initialisation d'un scaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train[X_train_numerical_vars] = scaler.fit_transform( X_train_numerical)\n",
    "    X_test[X_test_numerical_vars] = scaler.transform(X_test_numerical)\n",
    "\n",
    "\n",
    "    ##\n",
    "    # Hot One Encoding des variables catégorielles\n",
    "    X_train_encoded = pd.get_dummies(X_train, columns=cat_columns, dtype=int)\n",
    "    X_test_encoded = pd.get_dummies(X_test, columns=cat_columns, dtype=int)\n",
    "    # On aligne les colonnes de X_test_encoded sur celles de X_train_encoded\n",
    "    # pour s'assurer qu'ils ont les mêmes colonnes\n",
    "    X_test_encoded = X_test_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)\n",
    "\n",
    "\n",
    "    ##\n",
    "    # Transformation trigonométrique de 'year' et 'month' pour la saisonnalité\n",
    "    X_train_encoded['month_sin'] = np.sin(2 * np.pi * X_train_encoded['month'] / 12)\n",
    "    X_train_encoded['month_cos'] = np.cos(2 * np.pi * X_train_encoded['month'] / 12)\n",
    "    X_train_encoded['year_sin'] = np.sin(2 * np.pi * (X_train_encoded['year'] - X_train_encoded['year'].min()) / \n",
    "                                    (X_train_encoded['year'].max() - X_train_encoded['year'].min() + 1))\n",
    "    X_train_encoded['year_cos'] = np.cos(2 * np.pi * (X_train_encoded['year'] - X_train_encoded['year'].min()) / \n",
    "                                    (X_train_encoded['year'].max() - X_train_encoded['year'].min() + 1))\n",
    "    \n",
    "    X_test_encoded['month_sin'] = np.sin(2 * np.pi * X_test_encoded['month'] / 12)\n",
    "    X_test_encoded['month_cos'] = np.cos(2 * np.pi * X_test_encoded['month'] / 12)\n",
    "    X_test_encoded['year_sin'] = np.sin(2 * np.pi * (X_test_encoded['year'] - X_test_encoded['year'].min()) / \n",
    "                                    (X_test_encoded['year'].max() - X_test_encoded['year'].min() + 1))\n",
    "    X_test_encoded['year_cos'] = np.cos(2 * np.pi * (X_test_encoded['year'] - X_test_encoded['year'].min()) / \n",
    "                                    (X_test_encoded['year'].max() - X_test_encoded['year'].min() + 1))\n",
    "\n",
    "    # Suppression des colonnes 'month' et 'year' après transformation\n",
    "    X_train_encoded = X_train_encoded.drop(columns=['month', 'year'])\n",
    "    X_test_encoded = X_test_encoded.drop(columns=['month', 'year'])\n",
    "\n",
    "    return X_train_encoded, X_test_encoded, X_test_no_encoding, y_train, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONSTRUCTION DU DATAFRAME FUTUR \"future_data\"\n",
    "## POUR LES PREDICTIONS DES 6 PROCHAINS MOIS\n",
    "############################################################\n",
    "\n",
    "def build_future_data(past_data):\n",
    "    unique_country_admin1 = past_data[['country', 'admin1']].drop_duplicates()\n",
    "\n",
    "    # On souhaite d'abord obtenir le dernier mois de la dernière l'année dans past_data\n",
    "    last_year = past_data['year'].max()\n",
    "    last_month = past_data[past_data['year'] == last_year]['month'].max()\n",
    "\n",
    "    # On crée ensuite une liste de dictionnaires pour les 6 prochains mois avec les colonnes explicatives vides\n",
    "    future_data_list = []\n",
    "\n",
    "    # On ajoute les 6 prochains mois à future_data_list avec les colonnes connues \"country\" et \"admin1\" remplies\n",
    "    for i in range(1, 7):\n",
    "        next_month = last_month + i\n",
    "        next_year = last_year\n",
    "        if next_month > 12:\n",
    "            next_month -= 12\n",
    "            next_year += 1\n",
    "        for _, row in unique_country_admin1.iterrows():\n",
    "            future_data_list.append({\n",
    "                'year': next_year, \n",
    "                'month': next_month, \n",
    "                'country': row['country'], \n",
    "                'admin1': row['admin1']\n",
    "            })\n",
    "\n",
    "    # On crée notre dataframe \"future_data\" à partir de la liste de dictionnaires\n",
    "    future_data = pd.DataFrame(future_data_list, columns=past_data.columns)\n",
    "\n",
    "    # On remplit les autres colonnes explicatives avec des valeurs manquantes\n",
    "    for col in past_data.columns:\n",
    "        if col not in ['year', 'month', 'country', 'admin1']:\n",
    "            future_data[col] = np.nan\n",
    "\n",
    "    # Liste des colonnes pour lesquelles on veut remplir les valeurs manquantes\n",
    "    # columns_to_fill = [\n",
    "    #     'total_events', 'fatalities', 'Civilians', 'External/Other Forces',\n",
    "    #     'Identity Militias', 'Political Militias',\n",
    "    #     'State Forces', 'Battles', 'Explosions/Remote violence',\n",
    "    #     'Strategic developments', 'Violence against civilians',\n",
    "    #     'total_events_lag_1', 'terrorist_events_lag_1',\n",
    "    #     'total_events_lag_2', 'terrorist_events_lag_2',\n",
    "    #     'total_events_lag_3', 'terrorist_events_lag_3',\n",
    "    #     'total_events_lag_4', 'terrorist_events_lag_4',\n",
    "    #     'total_events_lag_5', 'terrorist_events_lag_5',\n",
    "    #     'total_events_lag_6', 'terrorist_events_lag_6'\n",
    "    # ]\n",
    "\n",
    "    columns_to_fill = [\n",
    "        'fatalities', 'Civilians', 'External/Other Forces',\n",
    "        'Identity Militias', 'Political Militias',\n",
    "        'State Forces', 'Battles', 'Explosions/Remote violence',\n",
    "        'Strategic developments', 'Violence against civilians',\n",
    "        'total_events_lag_1', 'terrorist_events_lag_1',\n",
    "        'total_events_lag_2', 'terrorist_events_lag_2',\n",
    "        'total_events_lag_3', 'terrorist_events_lag_3',\n",
    "        'total_events_lag_4', 'terrorist_events_lag_4',\n",
    "        'total_events_lag_5', 'terrorist_events_lag_5',\n",
    "        'total_events_lag_6', 'terrorist_events_lag_6'\n",
    "    ]\n",
    "\n",
    "\n",
    "    # On groupe les données par 'country', 'admin1', 'month' pour calculer les moyennes dans past_data\n",
    "    grouped_data = past_data.groupby(['country', 'admin1', 'month']).mean().reset_index()\n",
    "\n",
    "    # On remplace les valeurs manquantes dans future_data par les moyennes correspondantes de past_data\n",
    "    # en fonction du mois. Ex : si on veut calculer les valeurs des variables du mois de juillet 2024,\n",
    "    # on va calculer la moyenne des variables des mois de juillet des années précédentes pour avoir des\n",
    "    # valeurs de test réalistes.\n",
    "    for index, row in future_data.iterrows():\n",
    "        country = row['country']\n",
    "        admin1 = row['admin1']\n",
    "        month = row['month']\n",
    "        for var in columns_to_fill:\n",
    "            mean_value = grouped_data[(grouped_data['country'] == country) & \n",
    "                                    (grouped_data['admin1'] == admin1) & \n",
    "                                    (grouped_data['month'] == month)][var].values\n",
    "            if len(mean_value) > 0:\n",
    "                future_data.at[index, var] = mean_value[0]\n",
    "\n",
    "    # Certaines valeurs sont manquantes car les combinaisons (country, admin1, month) n'existent pas\n",
    "    # on va donc créer un dataframe contenant les combinaisons uniques de (country, admin1, month) dans future_data\n",
    "    future_combinations = future_data[['country', 'admin1', 'month']].drop_duplicates()\n",
    "\n",
    "    # Puis un dataframe contenant les combinaisons uniques de (country, admin1, month) dans past_data\n",
    "    monthly_combinations = past_data[['country', 'admin1', 'month']].drop_duplicates()\n",
    "\n",
    "    # Ensuite on recherche les combinaisons présentes dans future_data mais absentes dans past_data\n",
    "    missing_combinations = future_combinations[~future_combinations.isin(monthly_combinations)].dropna()\n",
    "\n",
    "    # Affichage des combinaisons manquantes\n",
    "    # print(\"Combinaisons manquantes dans past_data :\\n\"missing_combinations)\n",
    "\n",
    "    # En fonction de ces combinaisons, on vient remplir les valeurs manquantes dans future_data\n",
    "    # à partir du calcul de la moyenne des autres mois pour la combinaison (country, admin1)\n",
    "    for index, row in missing_combinations.iterrows():\n",
    "        # Sélection des lignes correspondant à la combinaison de country et admin1 dans past_data\n",
    "        matching_rows = past_data[(past_data['country'] == row['country']) & (past_data['admin1'] == row['admin1'])]\n",
    "        # Calcul de la moyenne des valeurs des variables pour tous les mois existants\n",
    "        mean_values = matching_rows[columns_to_fill].mean()\n",
    "        # Remplissage des valeurs manquantes dans future_data avec la moyenne calculée\n",
    "        future_data.loc[(future_data['country'] == row['country']) & (future_data['admin1'] == row['admin1']) & (future_data['month'] == row['month']), columns_to_fill] = mean_values.values\n",
    "\n",
    "    # Enfin on remplace les NaN des lignes restantes par la valeur la plus fréquente dans chaque colonne\n",
    "    future_data = future_data.fillna(future_data.mode().iloc[0])\n",
    "\n",
    "    # On supprime la colonne de variable cible et on vérifie qu'il n'y a plus de NaN\n",
    "    future_data = future_data.drop(columns=['terrorist_events'])\n",
    "    future_data.info()\n",
    "\n",
    "    # On arrondit les valeurs calculées pour les variables explicatives afin d'obtenir des valeurs entières\n",
    "    future_data = future_data.round(0)\n",
    "\n",
    "    return future_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRANSFORMATION DES DONNEES DU DATAFRAME \"future_data\"\n",
    "############################################################\n",
    "\n",
    "def future_data_transformation(df, scaler):\n",
    "    ##\n",
    "    # Préparation du dataframe \"future_data\" pour le modèle de ML\n",
    "    future_data_encoded = df.copy()\n",
    "\n",
    "    # On standardise les variables numériques exceptées les variables catégorielles\n",
    "    # ainsi que l'année et le mois qui subiront une autre transformation\n",
    "    cat_columns=['country', 'admin1']\n",
    "    future_data_numerical_vars = [col for col in future_data_encoded.columns if col not in cat_columns + ['year', 'month']]\n",
    "    # Extraction des données numériques\n",
    "    future_data_numerical = df[future_data_numerical_vars].values\n",
    "\n",
    "    # On utilise le scaler ajusté sur les données d'entraînement pour transformer les données du dataframe\n",
    "    future_data_encoded[future_data_numerical_vars] = scaler.transform(future_data_numerical)\n",
    "\n",
    "    # Hot One Encoding des variables catégorielles\n",
    "    future_data_encoded = pd.get_dummies(future_data_encoded, columns=cat_columns, dtype=int)\n",
    "\n",
    "    # Transformation trigonométrique de 'year' et 'month' pour la saisonnalité\n",
    "    future_data_encoded['month_sin'] = np.sin(2 * np.pi * future_data_encoded['month'] / 12)\n",
    "    future_data_encoded['month_cos'] = np.cos(2 * np.pi * future_data_encoded['month'] / 12)\n",
    "    future_data_encoded['year_sin'] = np.sin(2 * np.pi * (future_data_encoded['year'] - future_data_encoded['year'].min()) / \n",
    "                                    (future_data_encoded['year'].max() - future_data_encoded['year'].min() + 1))\n",
    "    future_data_encoded['year_cos'] = np.cos(2 * np.pi * (future_data_encoded['year'] - future_data_encoded['year'].min()) / \n",
    "                                    (future_data_encoded['year'].max() - future_data_encoded['year'].min() + 1))\n",
    "\n",
    "    # Suppression des colonnes 'month' et 'year' après transformation\n",
    "    future_data_encoded = future_data_encoded.drop(columns=['month', 'year'])\n",
    "\n",
    "    return future_data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATION DES DATAFRAMES HISTORIQUES ET FUTURS\n",
    "############################################################\n",
    "\n",
    "# On applique les différentes étapes de préparation à notre dataframe initial\n",
    "df = load_dataset('../data/raw/terrorisme_sahel.csv')\n",
    "df = columns_filtering(df)\n",
    "df = add_new_colums_dates(df)\n",
    "df = add_new_colums_actors(df)\n",
    "df = add_new_colums_interaction(df)\n",
    "df = add_new_colums_terrorist_group(df)\n",
    "df = add_new_colums_pmc_group(df)\n",
    "df = delete_columns(df)\n",
    "df = fill_nan_values(df)\n",
    "\n",
    "# On crée notre dataframe qui sera utilisé pour entrainer notre modèle\n",
    "# sur les données historiques\n",
    "past_data = build_past_data(df)\n",
    "\n",
    "# On crée notre dataframe qui sera utilisé pour effectuer les prédictions\n",
    "# sur les 6 prochains mois\n",
    "future_data = build_future_data(past_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREDICTION POUR LES 6 PROCHAINS MOIS\n",
    "## AVEC UN MODELE RANDOM FOREST REGRESSOR\n",
    "## AVEC LDA\n",
    "############################################################\n",
    "\n",
    "# On récupère nos jeux d'entrainement et de test\n",
    "X_train_encoded, X_test_encoded, X_test_no_encoding, y_train, y_test, scaler = past_data_transformation(past_data)\n",
    "future_data_encoded = future_data_transformation(future_data, scaler)\n",
    "\n",
    "lda = LDA()\n",
    "X_train_lda = lda.fit_transform(X_train_encoded, y_train)\n",
    "X_test_lda = lda.transform(X_test_encoded)\n",
    "future_data_encoded_lda = lda.transform(future_data_encoded)\n",
    "\n",
    "# On entraine un modèle RF avec la LDA\n",
    "# avec les meilleurs paramètres du Gridsearch\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "rf.fit(X_train_lda, y_train)\n",
    "\n",
    "# Prédictions de la LDA\n",
    "y_pred_past_lda = rf.predict(X_test_lda)\n",
    "\n",
    "# Évaluation de la LDA sur les données historiques\n",
    "r2_lda = rf.score(X_test_lda, y_test)\n",
    "rmse_lda = np.sqrt(mean_squared_error(y_test, y_pred_past_lda))\n",
    "mae_lda = mean_absolute_error(y_test, y_pred_past_lda)\n",
    "pearson_corr_lda, _ = pearsonr(y_test, y_pred_past_lda)\n",
    "\n",
    "print(\"\\nRandom Forest LDA R2:\", r2_lda)\n",
    "print(\"Random Forest LDA RMSE:\", rmse_lda)\n",
    "print(\"Random Forest LDA MAE:\", mae_lda)\n",
    "print(\"Random Forest LDA Pearson Correlation:\", pearson_corr_lda)\n",
    "\n",
    "# On utilise notre modèle pour faire des prédictions sur future_data\n",
    "y_pred_future_lda = rf.predict(future_data_encoded_lda)\n",
    "\n",
    "# On ajoute les prédictions à notre dataframe future_data\n",
    "future_data['terrorist_events'] = y_pred_future_lda.round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pd.DataFrame({\"Feature\":  X_train_encoded.columns, \"Coefficient\": lda.coef_[0]})\n",
    "# Visualisation des coefficients\n",
    "plt.figure(figsize=(10, 15))\n",
    "plt.barh(coefficients['Feature'], sorted(coefficients['Coefficient']))\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Coefficients des features pour le modèle RF LDA')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation des résidus entre les prédictions et le réel pour les 6 derniers mois de nos data\n",
    "residu = y_pred_past_lda - y_test\n",
    "#plt.hist(residu, bins=25)\n",
    "sns.histplot(residu, kde=True)\n",
    "plt.xlabel('résidus= y_pred_past_lda - y_test')\n",
    "plt.title('Histogramme des résidus')\n",
    "_ = plt.ylabel('Count')\n",
    "# hétéroscédasticité des résidus, mais ce n'est pas rédibitoire pour l'utilisation du modéle, sachant les bons résultats des métrics ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation de la normalité de l'erreur\n",
    "import statsmodels.api as sm\n",
    "sm.qqplot(residu, fit = True, line = '45')\n",
    "plt.title(\"Etude de la normalité des résidus\")\n",
    "plt.show();\n",
    "# Les résidus pourraient s'approcher d'une loi normale entre -2 et 2, mais décroche qu-dessous de -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# On souhaite ajouter une colonne 'terrorist_events_last_6_months' à 'future_data' qui contient\n",
    "# la moyenne de 'terrorist_events' des 6 derniers mois pour chaque mois et sous-région\n",
    "\n",
    "# Convertir 'year' et 'month' en une seule colonne datetime pour faciliter le tri\n",
    "past_data['date'] = pd.to_datetime(past_data[['year', 'month']].assign(day=1))\n",
    "future_data['date'] = pd.to_datetime(future_data[['year', 'month']].assign(day=1))\n",
    "\n",
    "# Trier les données par 'admin1' et 'date'\n",
    "past_data = past_data.sort_values(by=['admin1', 'date'])\n",
    "future_data = future_data.sort_values(by=['admin1', 'date'])\n",
    "\n",
    "# Calculer la moyenne mobile sur les 6 derniers mois dans past_data\n",
    "past_data['terrorist_events_last_6_months'] = past_data.groupby('admin1')['terrorist_events'].transform(lambda x: x.rolling(window=6, min_periods=1).mean().round())\n",
    "\n",
    "# Obtenir les dernières valeurs de 'terrorist_events_last_6_months' pour chaque 'admin1'\n",
    "last_6_months_avg = past_data.groupby('admin1').apply(lambda x: x.set_index('date').resample('M').last().ffill().iloc[-1]['terrorist_events_last_6_months'])\n",
    "\n",
    "# Ajouter cette information à future_data\n",
    "future_data['terrorist_events_last_6_months'] = future_data['admin1'].map(last_6_months_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des prédictions par rapport au réel\n",
    "# par mois de Novembre 2023 à Avril 2024\n",
    "# au Mali, au Burkina Faso et au Niger\n",
    "# des les événements liés à des organisations terroristes\n",
    "\n",
    "# On ajoute les prédictions à l'ensemble de test\n",
    "df_test = X_test_no_encoding.copy()\n",
    "df_test['terrorist_events'] = y_test\n",
    "df_test['terrorist_events_pred'] = y_pred_past_lda\n",
    "\n",
    "# On convertit 'year' et 'month' en une colonne datetime 'event_date'\n",
    "df_test['event_date'] = pd.to_datetime(df_test[['year', 'month']].assign(day=1))\n",
    "\n",
    "# On regroupe les événements réels par mois\n",
    "real_events_by_month = df_test.groupby('event_date')['terrorist_events'].sum()\n",
    "\n",
    "# On regroupe les événements prédits par mois\n",
    "pred_events_by_month = df_test.groupby('event_date')['terrorist_events_pred'].sum()\n",
    "\n",
    "# On crée notre graphique\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(real_events_by_month.index, real_events_by_month.values, label='réel', linestyle='-', marker='o', color='blue')\n",
    "plt.plot(pred_events_by_month.index, pred_events_by_month.values, label='prédit', linestyle='--', marker='x', color='orange')\n",
    "plt.legend()\n",
    "plt.title(\"Evénements liés à des organisations terroristes, par mois de Novembre 2023 à Avril 2024, au Mali, au Burkina Faso et au Niger\")\n",
    "plt.xlabel('Mois')\n",
    "plt.ylabel(\"Nombre d'événements\")\n",
    "plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%b %Y'))\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import random\n",
    "\n",
    "all_data = pd.concat([past_data, future_data], axis=0, ignore_index=True)\n",
    "\n",
    "# Filtrer les données pour le Mali\n",
    "mali_all_data = all_data.loc[all_data['country'] == 'Mali']\n",
    "\n",
    "# Grouper les données filtrées par 'year', 'month', 'country' et 'admin1'\n",
    "# et calculer la somme des 'terrorist_events'\n",
    "mali_terrorist_events_by_admin = mali_all_data.groupby(['year', 'month', 'country', 'admin1'])['terrorist_events'].sum().reset_index()\n",
    "\n",
    "mali_terrorist_events_by_admin['date'] = pd.to_datetime(mali_terrorist_events_by_admin[['year', 'month']].assign(day=1))\n",
    "mali_terrorist_events_by_admin.set_index('date', inplace=True)\n",
    "# Visualisation des événements prédits\n",
    "number_of_colors = 15\n",
    "\n",
    "colors = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "             for i in range(number_of_colors)]\n",
    "\n",
    "dict_color = dict(zip(mali_all_data['admin1'].unique(), colors))\n",
    "legend_pops = []\n",
    "plt.figure(figsize=(20, 8))\n",
    "for admin in mali_all_data['admin1'].unique():\n",
    "    pred_by_admin = mali_terrorist_events_by_admin[mali_terrorist_events_by_admin['admin1'] == admin]\n",
    "    mali_pred_by_admin= pred_by_admin[(pred_by_admin['month'] >4) & (pred_by_admin['year'] == 2024)]\n",
    "    mali_past_by_admin= pred_by_admin[~((pred_by_admin['month'] >4) & (pred_by_admin['year'] == 2024))]\n",
    "    \n",
    "    plt.plot(mali_past_by_admin.index, mali_past_by_admin['terrorist_events'], linestyle='-', marker='x', color=dict_color[admin])\n",
    "    plt.plot(mali_pred_by_admin.index, mali_pred_by_admin['terrorist_events'], linestyle='--', marker='x', color=dict_color[admin])\n",
    "    legend_pops.append(mpatches.Patch(color=dict_color[admin], label=admin)) \n",
    "\n",
    "plt.legend(handles=legend_pops) \n",
    "\n",
    "plt.title(\"Evénements passés et prédits liés à des organisations terroristes, par mois de juin 2021 à Octobre 2024 au Mali, par administration territoriale\")\n",
    "plt.xlabel('Mois')\n",
    "plt.ylabel(\"Nombre d'événements par admin\")\n",
    "plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%b %Y'))\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les données pour le Burkina Faso\n",
    "bf_all_data = all_data.loc[all_data['country'] == 'Burkina Faso']\n",
    "\n",
    "# Grouper les données filtrées par 'year', 'month', 'country' et 'admin1'\n",
    "# et calculer la somme des 'terrorist_events'\n",
    "bf_terrorist_events_by_admin = bf_all_data.groupby(['year', 'month', 'country', 'admin1'])['terrorist_events'].sum().reset_index()\n",
    "\n",
    "bf_terrorist_events_by_admin['date'] = pd.to_datetime(bf_terrorist_events_by_admin[['year', 'month']].assign(day=1))\n",
    "bf_terrorist_events_by_admin.set_index('date', inplace=True)\n",
    "# Visualisation des événements prédits\n",
    "number_of_colors = 15\n",
    "\n",
    "colors = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "             for i in range(number_of_colors)]\n",
    "\n",
    "dict_color = dict(zip(bf_all_data['admin1'].unique(), colors))\n",
    "legend_pops = []\n",
    "plt.figure(figsize=(20, 8))\n",
    "for admin in bf_all_data['admin1'].unique():\n",
    "    pred_by_admin = bf_terrorist_events_by_admin[bf_terrorist_events_by_admin['admin1'] == admin]\n",
    "    bf_pred_by_admin= pred_by_admin[(pred_by_admin['month'] >4) & (pred_by_admin['year'] == 2024)]\n",
    "    bf_past_by_admin= pred_by_admin[~((pred_by_admin['month'] >4) & (pred_by_admin['year'] == 2024))]\n",
    "    \n",
    "    plt.plot(bf_past_by_admin.index, bf_past_by_admin['terrorist_events'], linestyle='-', marker='x', color=dict_color[admin])\n",
    "    plt.plot(bf_pred_by_admin.index, bf_pred_by_admin['terrorist_events'], linestyle='--', marker='x', color=dict_color[admin])\n",
    "    legend_pops.append(mpatches.Patch(color=dict_color[admin], label=admin)) \n",
    "\n",
    "plt.legend(handles=legend_pops) \n",
    "\n",
    "plt.title(\"Evénements passés et prédits liés à des organisations terroristes, par mois de juin 2021 à Octobre 2024 au Burkina Faso, par administration territoriale\")\n",
    "plt.xlabel('Mois')\n",
    "plt.ylabel(\"Nombre d'événements par admin\")\n",
    "plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%b %Y'))\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les données pour le Mali\n",
    "niger_all_data = all_data.loc[all_data['country'] == 'Niger']\n",
    "\n",
    "# Grouper les données filtrées par 'year', 'month', 'country' et 'admin1'\n",
    "# et calculer la somme des 'terrorist_events'\n",
    "niger_terrorist_events_by_admin = niger_all_data.groupby(['year', 'month', 'country', 'admin1'])['terrorist_events'].sum().reset_index()\n",
    "\n",
    "niger_terrorist_events_by_admin['date'] = pd.to_datetime(niger_terrorist_events_by_admin[['year', 'month']].assign(day=1))\n",
    "niger_terrorist_events_by_admin.set_index('date', inplace=True)\n",
    "# Visualisation des événements prédits\n",
    "number_of_colors = 15\n",
    "\n",
    "colors = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "             for i in range(number_of_colors)]\n",
    "\n",
    "dict_color = dict(zip(niger_all_data['admin1'].unique(), colors))\n",
    "legend_pops = []\n",
    "plt.figure(figsize=(20, 8))\n",
    "for admin in niger_all_data['admin1'].unique():\n",
    "    pred_by_admin = niger_terrorist_events_by_admin[niger_terrorist_events_by_admin['admin1'] == admin]\n",
    "    niger_pred_by_admin= pred_by_admin[(pred_by_admin['month'] >4) & (pred_by_admin['year'] == 2024)]\n",
    "    niger_past_by_admin= pred_by_admin[~((pred_by_admin['month'] >4) & (pred_by_admin['year'] == 2024))]\n",
    "    \n",
    "    plt.plot(niger_past_by_admin.index, niger_past_by_admin['terrorist_events'], linestyle='-', marker='x', color=dict_color[admin])\n",
    "    plt.plot(niger_pred_by_admin.index, niger_pred_by_admin['terrorist_events'], linestyle='--', marker='x', color=dict_color[admin])\n",
    "    legend_pops.append(mpatches.Patch(color=dict_color[admin], label=admin)) \n",
    "\n",
    "plt.legend(handles=legend_pops) \n",
    "\n",
    "plt.title(\"Evénements passés et prédits liés à des organisations terroristes, par mois de juin 2021 à Octobre 2024 au Niger, par administration territoriale\")\n",
    "plt.xlabel('Mois')\n",
    "plt.ylabel(\"Nombre d'événements par admin\")\n",
    "plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%b %Y'))\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Grouper les données filtrées par 'year', 'month', 'country' et 'admin1'\n",
    "# et calculer la somme des 'terrorist_events'\n",
    "terrorist_events_by_country = all_data.groupby(['year', 'month', 'country'])['terrorist_events'].sum().reset_index()\n",
    "\n",
    "terrorist_events_by_country ['date'] = pd.to_datetime(terrorist_events_by_country [['year', 'month']].assign(day=1))\n",
    "terrorist_events_by_country .set_index('date', inplace=True)\n",
    "# Visualisation des événements prédits\n",
    "number_of_colors = 15\n",
    "\n",
    "colors = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "             for i in range(number_of_colors)]\n",
    "\n",
    "dict_color = dict(zip(all_data['country'].unique(), colors))\n",
    "legend_pops = []\n",
    "plt.figure(figsize=(20, 8))\n",
    "for country in all_data['country'].unique():\n",
    "    data_by_country = terrorist_events_by_country[terrorist_events_by_country['country'] == country]\n",
    "    future_pred_by_country = data_by_country[(data_by_country['month'] >4) & (data_by_country['year'] == 2024)]\n",
    "    past_by_country = data_by_country[~((data_by_country['month'] >4) & (data_by_country['year'] == 2024))]\n",
    "    \n",
    "    plt.plot(past_by_country.index, past_by_country['terrorist_events'], linestyle='-', marker='x', color=dict_color[country])\n",
    "    plt.plot(future_pred_by_country.index, future_pred_by_country['terrorist_events'], linestyle='--', marker='x', color=dict_color[country])\n",
    "    legend_pops.append(mpatches.Patch(color=dict_color[country], label=country)) \n",
    "\n",
    "plt.legend(handles=legend_pops) \n",
    "\n",
    "plt.title(\"Evénements passés et prédits liés à des organisations terroristes, par mois de juin 2021 à Octobre 2024 par pays\")\n",
    "plt.xlabel('Mois')\n",
    "plt.ylabel(\"Nombre d'événements par admin\")\n",
    "plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%b %Y'))\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VISUALISATION DES PREDICTIONS SUR UNE CARTE\n",
    "############################################################\n",
    "\n",
    "##\n",
    "# D'abord on essaie d'identifier chaque sous-région du Mali\n",
    "\n",
    "# On charge les fichiers .shp pour les sous-régions du Mali\n",
    "gdf_mali = gpd.read_file('../references/mali_admin1.shp')\n",
    "\n",
    "\n",
    "# On trace les sous-régions du Mali avec leurs identifiants\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "gdf_mali.plot(ax=ax, edgecolor='k')\n",
    "\n",
    "# On ajoute les labels des identifiants sur chaque sous-région\n",
    "for idx, row in gdf_mali.iterrows():\n",
    "    plt.annotate(text=idx, xy=(row.geometry.centroid.x, row.geometry.centroid.y),\n",
    "                 horizontalalignment='center', fontsize=9, color='white')\n",
    "\n",
    "plt.title('Sous-régions du Mali avec identifiants')\n",
    "plt.show();\n",
    "\n",
    "# On affiche les différentes valeurs prises par admin1 afin d'identifier\n",
    "# chaque sous-région sur la carte et d'associer au nom l'identifiant correspondant\n",
    "# grâce à une autre carte (source : Wikipédia) du Mali\n",
    "future_data_mali = future_data[future_data['country'] == 'Mali']\n",
    "print(\"Nom des sous-région du Mali :\\n\", future_data_mali['admin1'].unique())\n",
    "\n",
    "mapping_mali = {\n",
    "    'Bamako': 0,\n",
    "    'Gao': 1,\n",
    "    'Kayes': 2,\n",
    "    'Kidal': 3,\n",
    "    'Koulikoro': 4,\n",
    "    'Menaka': 1,\n",
    "    'Mopti': 5,\n",
    "    'Segou': 6,\n",
    "    'Sikasso': 7,\n",
    "    'Tombouctou': 8\n",
    "}\n",
    "\n",
    "# On applique le mapping à notre dataframe qui contient les données pour le Mali\n",
    "future_data_mali_geo = map_regions_to_ids(future_data_mali, mapping_mali)\n",
    "\n",
    "# On fusionne les données géographiques avec les prédictions\n",
    "gdf_combined_mali = gdf_mali.merge(future_data_mali_geo, how='left', left_index=True, right_on='region_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Puis on essaie d'identifier chaque sous-région du Burkina Faso\n",
    "\n",
    "# On charge les fichiers .shp pour les sous-régions du Burkina\n",
    "gdf_burkina = gpd.read_file('../references/burkina_faso_admin1.shp')\n",
    "\n",
    "\n",
    "# On trace les sous-régions du Burkina avec leurs identifiants\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "gdf_burkina.plot(ax=ax, edgecolor='k')\n",
    "\n",
    "# On ajoute les labels des identifiants sur chaque sous-région\n",
    "for idx, row in gdf_burkina.iterrows():\n",
    "    plt.annotate(text=idx, xy=(row.geometry.centroid.x, row.geometry.centroid.y),\n",
    "                 horizontalalignment='center', fontsize=9, color='white')\n",
    "\n",
    "plt.title('Sous-régions du Burkina Faso avec identifiants')\n",
    "plt.show();\n",
    "\n",
    "# On affiche les différentes valeurs prises par admin1 afin d'identifier\n",
    "# chaque sous-région sur la carte et d'associer au nom l'identifiant correspondant\n",
    "# grâce à une autre carte (source : Wikipédia) du Burkina\n",
    "future_data_burkina = future_data[future_data['country'] == 'Burkina Faso']\n",
    "print(\"Nom des sous-région du Burkina Faso :\\n\", future_data_burkina['admin1'].unique())\n",
    "\n",
    "mapping_burkina = {\n",
    "    'Boucle du Mouhoun': 0,\n",
    "    'Cascades': 1,\n",
    "    'Centre': 2,\n",
    "    'Centre-Est': 3,\n",
    "    'Centre-Nord': 4,\n",
    "    'Centre-Ouest': 5,\n",
    "    'Centre-Sud': 6,\n",
    "    'Est': 7,\n",
    "    'Hauts-Bassins': 8,\n",
    "    'Nord': 9,\n",
    "    'Plateau-Central': 10,\n",
    "    'Sahel': 11,\n",
    "    'Sud-Ouest': 12\n",
    "}\n",
    "\n",
    "# On applique le mapping à notre dataframe qui contient les données pour le Burkina\n",
    "future_data_burkina_geo = map_regions_to_ids(future_data_burkina, mapping_burkina)\n",
    "\n",
    "# On fusionne les données géographiques avec les prédictions\n",
    "gdf_combined_burkina = gdf_burkina.merge(future_data_burkina_geo, how='left', left_index=True, right_on='region_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Ensuite on essaie d'identifier chaque sous-région du Niger\n",
    "\n",
    "# On charge les fichiers .shp pour les sous-régions du Niger\n",
    "gdf_niger = gpd.read_file('../references/niger_admin1.shp')\n",
    "\n",
    "\n",
    "# On trace les sous-régions du Niger avec leurs identifiants\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "gdf_niger.plot(ax=ax, edgecolor='k')\n",
    "\n",
    "# On ajoute les labels des identifiants sur chaque sous-région\n",
    "for idx, row in gdf_niger.iterrows():\n",
    "    plt.annotate(text=idx, xy=(row.geometry.centroid.x, row.geometry.centroid.y),\n",
    "                 horizontalalignment='center', fontsize=9, color='white')\n",
    "\n",
    "plt.title('Sous-régions du Niger avec identifiants')\n",
    "plt.show();\n",
    "\n",
    "# On affiche les différentes valeurs prises par admin1 afin d'identifier\n",
    "# chaque sous-région sur la carte et d'associer au nom l'identifiant correspondant\n",
    "# grâce à une autre carte (source : Wikipédia) du Niger\n",
    "future_data_niger = future_data[future_data['country'] == 'Niger']\n",
    "print(\"Nom des sous-région du Niger :\\n\", future_data_niger['admin1'].unique())\n",
    "\n",
    "mapping_niger = {\n",
    "    'Agadez': 0,\n",
    "    'Diffa': 1,\n",
    "    'Dosso': 2,\n",
    "    'Maradi': 3,\n",
    "    'Niamey': 4,\n",
    "    'Tahoua': 5,\n",
    "    'Tillaberi': 6,\n",
    "    'Zinder': 7\n",
    "}\n",
    "\n",
    "# On applique le mapping à notre dataframe qui contient les données pour le Niger\n",
    "future_data_niger_geo = map_regions_to_ids(future_data_niger, mapping_niger)\n",
    "\n",
    "# On fusionne les données géographiques avec les prédictions\n",
    "gdf_combined_niger = gdf_niger.merge(future_data_niger_geo, how='left', left_index=True, right_on='region_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On fusionne les GeoDataFrames de tous les pays en un seul GeoDataFrame\n",
    "gdf_combined = pd.concat([gdf_combined_niger, gdf_combined_mali, gdf_combined_burkina], axis=0, ignore_index=True)\n",
    "\n",
    "# On vérifie que nos données sont bien du type attendu pour l'affichage sur notre map\n",
    "gdf_combined['region_id'] = gdf_combined['region_id'].astype(int)\n",
    "gdf_combined['month'] = gdf_combined['month'].astype(int)\n",
    "gdf_combined['terrorist_events'] = gdf_combined['terrorist_events'].astype(int)\n",
    "gdf_combined['terrorist_events_last_6_months'] = gdf_combined['terrorist_events_last_6_months'].astype(int)\n",
    "gdf_combined['admin1'] = gdf_combined['admin1'].astype(str)\n",
    "\n",
    "# On retire les colonnes non nécessaires\n",
    "columns_to_keep = ['geometry', 'region_id', 'month', 'terrorist_events', 'terrorist_events_last_6_months', 'admin1']\n",
    "gdf_combined = gdf_combined[columns_to_keep]\n",
    "\n",
    "# On crée une map qui permettra de visualiser pour chaque sous-région des 3 pays\n",
    "# contenue dans notre GéoDataframe le nombre d'évènements liés à des organisations terroristes\n",
    "fig = px.choropleth_mapbox(\n",
    "    gdf_combined,\n",
    "    geojson=gdf_combined.geometry.__geo_interface__,\n",
    "    locations=gdf_combined.index,\n",
    "    color='terrorist_events',\n",
    "    animation_frame='month',\n",
    "    hover_data={\n",
    "        'region_id': False,\n",
    "        'admin1': True,\n",
    "        'month': True,\n",
    "        'terrorist_events': True ,\n",
    "        'terrorist_events_last_6_months': True\n",
    "    },\n",
    "    title=\"Prédiction des événements impliquant des organisations terroristes pour les 6 prochains mois, par région\",\n",
    "    color_continuous_scale='Plasma',\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    center={\"lat\": 15, \"lon\": -1.5},\n",
    "    zoom=5,\n",
    "    opacity=0.5,\n",
    "    labels={\n",
    "        'terrorist_events': 'Événements terroristes',\n",
    "        'terrorist_events_last_6_months': 'Événements terroristes 6 derniers mois (moyenne)'\n",
    "        }\n",
    ")\n",
    "\n",
    "# On ajuste la taille de la carte\n",
    "fig.update_layout(\n",
    "    height=800,\n",
    "    width=1000\n",
    ")\n",
    "\n",
    "# On affiche la carte interactive\n",
    "fig.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
